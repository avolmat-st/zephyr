/*
 * Copyright (c) 2025 STMicroelectronics.
 *
 * SPDX-License-Identifier: Apache-2.0
 */

#include <errno.h>

#include <zephyr/kernel.h>
#include <zephyr/irq.h>
#include <zephyr/drivers/clock_control/stm32_clock_control.h>
#include <zephyr/drivers/clock_control.h>
#include <zephyr/drivers/reset.h>
#include <zephyr/drivers/video.h>
#include <zephyr/drivers/video-controls.h>
#include <zephyr/logging/log.h>

#include "video_ctrls.h"
#include "video_device.h"

#define DT_DRV_COMPAT st_stm32_jpeg

#define STM32_JPEG_DEFAULT_WIDTH	640
#define STM32_JPEG_DEFAULT_HEIGHT	480
#define STM32_JPEG_DEFAULT_IN_FMT	VIDEO_PIX_FMT_NV12
#define STM32_JPEG_DEFAULT_OUT_FMT	VIDEO_PIX_FMT_JPEG

LOG_MODULE_REGISTER(stm32_jpeg, CONFIG_VIDEO_LOG_LEVEL);

typedef void (*irq_config_func_t)(const struct device *dev);

enum stm32_jpeg_state {
	STM32_JPEG_STOPPED = 0,
	STM32_JPEG_WAIT_FOR_BUFFER,
	STM32_JPEG_RUNNING,
};

struct video_common_hdr {
	struct video_format fmt;
	struct video_queue queue;
};

struct video_m2m_common_hdr {
	struct video_common_hdr in;
	struct video_common_hdr out;
};

#define YCBCR_420_MCU_BLOCK_SIZE	384	/* 4 8x8 Y, 1 8x8 Cb, 1 8x8 Cr */
struct stm32_jpeg_data {
	struct video_m2m_common_hdr m2m;
	const struct device *dev;
	JPEG_HandleTypeDef hjpeg;
	struct k_mutex lock;
	enum stm32_jpeg_state state;
	struct video_buffer *current_in;
	struct video_buffer *current_out;

	struct video_ctrl jpeg_quality;

	uint32_t current_x_mcu;
	uint32_t current_y_mcu;
	uint8_t mcu_ycbcr[YCBCR_420_MCU_BLOCK_SIZE];
};

struct stm32_jpeg_config {
	const struct stm32_pclken jpeg_hclken;
	irq_config_func_t irq_config;
	const struct reset_dt_spec reset_jpeg;
};

struct stm32_jpeg_fmt_conf {
	uint32_t pixelformat;
	uint32_t subsampling;
	uint8_t hmcu_div;
	uint8_t vmcu_div;
};

static struct stm32_jpeg_fmt_conf stm32_jpeg_confs[] = {
	/* JPEG */
	{
		.pixelformat = VIDEO_PIX_FMT_JPEG,
		/* Meaningless but set to 1 to make set_fmt check working */
		.hmcu_div = 1,
		.vmcu_div = 1,
	},
	/* YCrCb 4:2:0 */
	{
		.pixelformat = VIDEO_PIX_FMT_NV12,
		.subsampling = JPEG_420_SUBSAMPLING,
		.hmcu_div = 16,
		.vmcu_div = 16,
	},
	/* TODO: YCrCb 4:2:2 to be added */
	/* TODO: YCrCb 4:4:4 to be added */
};

#define MCU_WIDTH	16
#define MCU_HEIGHT	16
#define MCU_BLOCK_SZ	8
static void stm32_jpeg_nv12_to_ycbcr_mcu(const uint8_t mcu_x, const uint8_t mcu_y,
					 const uint8_t *in_y, const uint8_t *in_uv,
					 uint8_t *out, uint32_t width)
{
	int mcu_idx = 0;

	/* Copy the 4 8x8 Y */
	for (int by = 0; by < 2; ++by) {
		for (int bx = 0; bx < 2; ++bx) {
			for (int y = 0; y < MCU_BLOCK_SZ; ++y) {
				int src_y = mcu_y * MCU_HEIGHT + by * MCU_BLOCK_SZ + y;
				int src_x = mcu_x * MCU_WIDTH + bx * MCU_BLOCK_SZ;
				const uint8_t *src = in_y + src_y * width + src_x;
				uint8_t *dst = out + mcu_idx;

				memcpy(dst, src, MCU_BLOCK_SZ);
				mcu_idx += MCU_BLOCK_SZ;
			}
		}
	}

	/* Copy 1 8x8 Cb block */
	for (int y = 0; y < MCU_BLOCK_SZ; ++y) {
		int src_y = (mcu_y * MCU_HEIGHT) / 2 + y;
		int src_x = (mcu_x * MCU_WIDTH) / 2;
		const uint8_t *src = in_uv + (src_y * width) + (src_x * 2);
		uint8_t *dst = out + mcu_idx;

		for (int x = 0; x < MCU_BLOCK_SZ; ++x) {
			dst[x] = src[x * 2];
		}
		mcu_idx += MCU_BLOCK_SZ;
	}

	/* Copy 1 8x8 Cr block */
	for (int y = 0; y < MCU_BLOCK_SZ; ++y) {
		int src_y = (mcu_y * MCU_HEIGHT) / 2 + y;
		int src_x = (mcu_x * MCU_WIDTH) / 2;
		const uint8_t *src = in_uv + (src_y * width) + (src_x * 2);
		uint8_t *dst = out + mcu_idx;

		for (int x = 0; x < MCU_BLOCK_SZ; ++x) {
			dst[x] = src[x * 2 + 1];
		}
		mcu_idx += MCU_BLOCK_SZ;
	}
}

static struct stm32_jpeg_fmt_conf *stm32_jpeg_get_conf(uint32_t pixelformat)
{
	for (int i = 0; i < ARRAY_SIZE(stm32_jpeg_confs); i++) {
		if (stm32_jpeg_confs[i].pixelformat == pixelformat) {
			return &stm32_jpeg_confs[i];
		}
	}

	return NULL;
}

static int stm32_jpeg_m2m_codec(const struct device *dev, struct video_buffer *in,
				struct video_buffer *out)
{
	struct stm32_jpeg_data *data = dev->data;
	JPEG_ConfTypeDef Conf = {0};
	int ret;

	data->current_in = in;
	data->current_out = out;

	if (data->m2m.in.fmt.pixelformat != VIDEO_PIX_FMT_JPEG) {
		struct stm32_jpeg_fmt_conf *conf =
			stm32_jpeg_get_conf(data->m2m.in.fmt.pixelformat);
		HAL_StatusTypeDef hret;

		/* Reset value of current MCU and output buffer offset */
		data->current_x_mcu = 0;
		data->current_y_mcu = 0;

		/* JPEG Encoding */
		Conf.ColorSpace = JPEG_YCBCR_COLORSPACE;
		Conf.ChromaSubsampling = conf->subsampling;
		Conf.ImageWidth = data->m2m.in.fmt.width;
		Conf.ImageHeight = data->m2m.in.fmt.height;
		Conf.ImageQuality = data->jpeg_quality.val;

		hret = HAL_JPEG_ConfigEncoding(&data->hjpeg, &Conf);
		if (hret != HAL_OK) {
			LOG_ERR("Failed to configure codec for encoding");
			ret = -EIO;
			goto error;
		}

		data->state = STM32_JPEG_RUNNING;

		/* Convert one MCU at a time */
		stm32_jpeg_nv12_to_ycbcr_mcu(data->current_x_mcu++, data->current_y_mcu,
					     data->current_in->buffer, data->current_in->buffer +
					     data->m2m.in.fmt.width * data->m2m.in.fmt.height,
					     data->mcu_ycbcr, data->m2m.in.fmt.width);
		if (data->current_x_mcu >= data->m2m.in.fmt.width / MCU_WIDTH) {
			data->current_x_mcu = 0;
			data->current_y_mcu++;
		}

		hret = HAL_JPEG_Encode_IT(&data->hjpeg, data->mcu_ycbcr, YCBCR_420_MCU_BLOCK_SIZE,
					  data->current_out->buffer, data->current_out->size);
		if (hret != HAL_OK) {
			LOG_ERR("Failed to request encoding");
			ret = -EIO;
			goto error;
		}
	} else {
		LOG_ERR("Decoder not yet implemented");
		ret = -EINVAL;
		goto error;
	}

	return 0;

error:
	data->state = STM32_JPEG_WAIT_FOR_BUFFER;
	return ret;
}

/* Function called when the data have been generated by the JPEG block */
void HAL_JPEG_DataReadyCallback(JPEG_HandleTypeDef *hjpeg, uint8_t *pDataOut,
				uint32_t OutDataLength)
{
	struct stm32_jpeg_data *data =
			CONTAINER_OF(hjpeg, struct stm32_jpeg_data, hjpeg);

	k_mutex_lock(&data->lock, K_FOREVER);

	/* Store the output data size and timestamp */
	data->current_out->bytesused = OutDataLength;
	data->current_out->timestamp = k_uptime_get_32();

	k_mutex_unlock(&data->lock);
}

/*
 * Function called when all processing is finished, at that moment we can be
 * sure that buffers won't be used anymore
 */
void HAL_JPEG_EncodeCpltCallback(JPEG_HandleTypeDef *hjpeg)
{
	struct stm32_jpeg_data *data = CONTAINER_OF(hjpeg, struct stm32_jpeg_data, hjpeg);
	int ret = 0;

	k_mutex_lock(&data->lock, K_FOREVER);

	/* Give back the buffers to the application */
	video_queue_done(&data->m2m.in.queue, data->current_in);
	video_queue_done(&data->m2m.out.queue, data->current_out);

	/* Try to restart the next processing if needed */
	ret = stm32_jpeg_start_codec(data->dev);
	if (ret) {
		LOG_ERR("Failed to start codec, err: %d", ret);
		goto out;
	}

out:
	k_mutex_unlock(&data->lock);
}

void HAL_JPEG_ErrorCallback(JPEG_HandleTypeDef *hjpeg)
{
	__ASSERT(false, "Got %s", __func__);
}

/*
 * This function is called whenever new input data (MCU) must be given in
 * order to proceed the frame
 */
void HAL_JPEG_GetDataCallback(JPEG_HandleTypeDef *hjpeg, uint32_t NbEncodedData)
{
	struct stm32_jpeg_data *data =
			CONTAINER_OF(hjpeg, struct stm32_jpeg_data, hjpeg);

	/* Convert one MCU at a time */
	stm32_jpeg_nv12_to_ycbcr_mcu(data->current_x_mcu++, data->current_y_mcu,
				     data->current_in->buffer, data->current_in->buffer +
				     data->m2m.in.fmt.width * data->m2m.in.fmt.height,
				     data->mcu_ycbcr, data->m2m.in.fmt.width);
	if (data->current_x_mcu >= data->m2m.in.fmt.width / MCU_WIDTH) {
		data->current_x_mcu = 0;
		data->current_y_mcu++;
	}

	HAL_JPEG_ConfigInputBuffer(hjpeg, data->mcu_ycbcr, YCBCR_420_MCU_BLOCK_SIZE);
}

static int stm32_jpeg_get_fmt(const struct device *dev, struct video_format *fmt)
{
	struct stm32_jpeg_data *data = dev->data;

	*fmt = fmt->type == VIDEO_BUF_TYPE_INPUT ? data->m2m.in.fmt : data->m2m.out.fmt;

	return 0;
}

static int stm32_jpeg_set_fmt(const struct device *dev, struct video_format *fmt)
{
	struct stm32_jpeg_data *data = dev->data;
	struct video_common_hdr *common =
		fmt->type == VIDEO_BUF_TYPE_INPUT ? &data->m2m.in : &data->m2m.out;
	struct stm32_jpeg_fmt_conf *conf;
	int ret = 0;

	/* Validate the settings */
	conf = stm32_jpeg_get_conf(fmt->pixelformat);
	if (conf == NULL) {
		return -EINVAL;
	}
	if (fmt->width % conf->hmcu_div || fmt->height % conf->vmcu_div) {
		LOG_ERR("Format %s: %d pixels width / %d pixels height multiple required",
			VIDEO_FOURCC_TO_STR(fmt->pixelformat), conf->hmcu_div, conf->vmcu_div);
		return -EINVAL;
	}

	k_mutex_lock(&data->lock, K_FOREVER);

	if (common->is_streaming) {
		ret = -EBUSY;
		goto out;
	}

	common->fmt = *fmt;

out:
	k_mutex_unlock(&data->lock);

	return ret;
}

static int stm32_jpeg_set_stream(const struct device *dev, bool enable, enum video_buf_type type)
{
	struct stm32_jpeg_data *data = dev->data;
	struct video_common_hdr *common =
		type == VIDEO_BUF_TYPE_INPUT ? &data->m2m.in : &data->m2m.out;
	int ret = 0;

	k_mutex_lock(&data->lock, K_FOREVER);

	/* Check that input / output formats are correct */
	if ((data->m2m.in.fmt.pixelformat == VIDEO_PIX_FMT_JPEG &&
	     data->m2m.out.fmt.pixelformat == VIDEO_PIX_FMT_JPEG) ||
	    (data->m2m.in.fmt.pixelformat != VIDEO_PIX_FMT_JPEG &&
	     data->m2m.out.fmt.pixelformat != VIDEO_PIX_FMT_JPEG)) {
		LOG_ERR("One of input or output format must be JPEG");
		ret = -EINVAL;
		goto out;
	}

	/* FIXME - temporary until the decoder support get added */
	if (data->m2m.in.fmt.pixelformat == VIDEO_PIX_FMT_JPEG) {
		LOG_ERR("Decoder not yet implemented");
		ret = -EIO;
		goto out;
	}

	if ((enable && common->is_streaming) || (!enable && !common->is_streaming)) {
		ret = -EALREADY;
		goto out;
	}

	common->is_streaming = enable;

	data->state = STM32_JPEG_WAIT_FOR_BUFFER;

out:
	k_mutex_unlock(&data->lock);

	return ret;
}

static const struct video_format_cap stm32_jpeg_fmts[] = {
	{
		.pixelformat = VIDEO_PIX_FMT_JPEG,
		.width_min = 1,
		.width_max = 65535,
		.height_min = 1,
		.height_max = 65535,
		.width_step = 1,
		.height_step = 1,
	},
	{
		.pixelformat = VIDEO_PIX_FMT_NV12,
		.width_min = 16,
		.width_max = 65520,
		.height_min = 16,
		.height_max = 65520,
		.width_step = 16,
		.height_step = 16,
	},
	{0}
};

static int stm32_jpeg_get_caps(const struct device *dev, struct video_caps *caps)
{
	caps->format_caps = stm32_jpeg_fmts;

	caps->min_vbuf_count = 1;
	caps->min_line_count = LINE_COUNT_HEIGHT;
	caps->max_line_count = LINE_COUNT_HEIGHT;

	return 0;
}

static DEVICE_API(video, stm32_jpeg_driver_api) = {
	.set_format = stm32_jpeg_set_fmt,
	.get_format = stm32_jpeg_get_fmt,
	.set_stream = stm32_jpeg_set_stream,
	.enqueue = video_m2m_enqueue,
	.dequeue = video_m2m_dequeue,
	.get_caps = stm32_jpeg_get_caps,
	.m2m_codec = stm32_jpeg_m2m_codec,
};

static int stm32_jpeg_enable_clock(const struct device *dev)
{
	const struct stm32_jpeg_config *config = dev->config;
	const struct device *cc_node = DEVICE_DT_GET(STM32_CLOCK_CONTROL_NODE);

	if (!device_is_ready(cc_node)) {
		LOG_ERR("clock control device not ready");
		return -ENODEV;
	}

	/* Turn on JPEG peripheral clock */
	return clock_control_on(cc_node, (clock_control_subsys_t)&config->jpeg_hclken);
}

static int stm32_jpeg_init(const struct device *dev)
{
	const struct stm32_jpeg_config *cfg = dev->config;
	struct stm32_jpeg_data *data = dev->data;
	HAL_StatusTypeDef hret;
	int ret;

	data->dev = dev;

	/* Enable DCMIPP / CSI clocks */
	ret = stm32_jpeg_enable_clock(dev);
	if (ret < 0) {
		LOG_ERR("Clock enabling failed.");
		return ret;
	}

	/* Reset JPEG */
	if (!device_is_ready(cfg->reset_jpeg.dev)) {
		LOG_ERR("reset controller not ready");
		return -ENODEV;
	}
	reset_line_toggle_dt(&cfg->reset_jpeg);

	/* Run IRQ init */
	cfg->irq_config(dev);

#if defined(CONFIG_SOC_SERIES_STM32N6X)
	HAL_RIF_RISC_SetSlaveSecureAttributes(RIF_RISC_PERIPH_INDEX_JPEG,
					      RIF_ATTRIBUTE_PRIV | RIF_ATTRIBUTE_SEC);
#endif

	/* Initialise default input / output formats */
	k_mutex_init(&data->lock);
	video_queue_init(&data->m2m.in.queue);
	video_queue_init(&data->m2m.out.queue);

	/* Initialize default formats */
	data->m2m.in.fmt.type = VIDEO_BUF_TYPE_INPUT;
	data->m2m.in.fmt.width = STM32_JPEG_DEFAULT_WIDTH;
	data->m2m.in.fmt.height = STM32_JPEG_DEFAULT_HEIGHT;
	data->m2m.in.fmt.pixelformat = STM32_JPEG_DEFAULT_IN_FMT;
	data->m2m.out.fmt.type = VIDEO_BUF_TYPE_OUTPUT;
	data->m2m.out.fmt.width = STM32_JPEG_DEFAULT_WIDTH;
	data->m2m.out.fmt.height = STM32_JPEG_DEFAULT_HEIGHT;
	data->m2m.out.fmt.pixelformat = STM32_JPEG_DEFAULT_OUT_FMT;

	ret = video_init_ctrl(&data->jpeg_quality, dev, VIDEO_CID_JPEG_COMPRESSION_QUALITY,
			      (struct video_ctrl_range) {.min = 5, .max = 100,
							 .step = 1, .def = 50});
	if (ret) {
		return ret;
	}

	/* Initialize JPEG peripheral */
	hret = HAL_JPEG_Init(&data->hjpeg);
	if (hret != HAL_OK) {
		LOG_ERR("JPEG initialization failed.");
		return -EIO;
	}

	LOG_DBG("%s initialized", dev->name);

	return 0;
}

static void stm32_jpeg_isr(const struct device *dev)
{
	struct stm32_jpeg_data *jpeg = dev->data;

	HAL_JPEG_IRQHandler(&jpeg->hjpeg);
}

#define STM32_JPEG_INIT(n)							\
	static void stm32_jpeg_irq_config_##n(const struct device *dev)		\
	{									\
		IRQ_CONNECT(DT_INST_IRQN(n), DT_INST_IRQ(n, priority),		\
			    stm32_jpeg_isr, DEVICE_DT_INST_GET(n), 0);		\
		irq_enable(DT_INST_IRQN(n));					\
	}									\
										\
	static struct stm32_jpeg_data stm32_jpeg_data_##n = {			\
		.hjpeg = {							\
			.Instance = (JPEG_TypeDef *)DT_INST_REG_ADDR(n),	\
		},								\
	};									\
										\
	static const struct stm32_jpeg_config stm32_jpeg_config_##n = {		\
		.jpeg_hclken =							\
			{.bus = DT_CLOCKS_CELL(DT_DRV_INST(n), bus),		\
			 .enr = DT_CLOCKS_CELL(DT_DRV_INST(n), bits)},		\
		.irq_config = stm32_jpeg_irq_config_##n,			\
		.reset_jpeg = RESET_DT_SPEC_INST_GET_BY_IDX(n, 0),		\
	};									\
										\
	DEVICE_DT_INST_DEFINE(n, &stm32_jpeg_init,				\
			      NULL, &stm32_jpeg_data_##n,			\
			      &stm32_jpeg_config_##n,				\
			      POST_KERNEL, CONFIG_VIDEO_INIT_PRIORITY,		\
			      &stm32_jpeg_driver_api);				\
										\
	VIDEO_DEVICE_DEFINE(jpeg_##n, DEVICE_DT_INST_GET(n), NULL);

DT_INST_FOREACH_STATUS_OKAY(STM32_JPEG_INIT)
